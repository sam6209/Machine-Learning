{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##一、tensor\n",
    "##1.Tensor类应该是最基本最核心的数据结构了，他表示的是一个操作的输出，但是他并不接收操作输出的值，\n",
    "##而是提供了在TensorFlow的Session中计算这些值的方法。 \n",
    "##2.在图被“投放”进一个Session中后，Tensor的值能够通过把Tensor传到Seesion.run（）这个函数里面去得到结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a [[1. 2. 3.]]\n",
      "b [[1.]\n",
      " [2.]\n",
      " [3.]]\n",
      "c [[14.]]\n",
      "c shape 1 1\n",
      "Const_10:0\n"
     ]
    }
   ],
   "source": [
    "#二、tf.constant(value,dtype=None,shape=None,name=’Const’)\n",
    "# value: 一个dtype类型的常量值／列表。要是value是一个列表的话，那么列表的长度不能够超过形状参数指定的大小（如果指定了）。要是列表长度小于指定的，那么多余的由列表的最后一个元素来填充。 \n",
    "# dtype: 返回tensor的类型 \n",
    "# shape: 返回的tensor形状。 \n",
    "# name: tensor的名字 \n",
    "\n",
    "a=tf.constant([1,2,3],shape=[1,3],dtype=np.float32)\n",
    "b=tf.constant([1,2,3],shape=[3,1],dtype=np.float32)\n",
    "c=tf.matmul(a,b)\n",
    "sess1=tf.Session()\n",
    "sess2=tf.Session()\n",
    "\n",
    "print \"a\", sess1.run(a)\n",
    "print \"b\", sess1.run(b)\n",
    "print \"c\", sess1.run(c)\n",
    "print \"c shape\", c.shape[0], c.shape[1]\n",
    "print a.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [[1 2]]\n",
      "x: [[2]\n",
      " [1]]\n",
      "y: [[4]]\n",
      "[[1. 2. 3.]]\n"
     ]
    }
   ],
   "source": [
    "#三、tf.Variable(initial_value=None,initializer=None,dtype=None,name=None)\n",
    "#Variable()这个构造函数需要初始值，这个初始值可以是一个任何类型任何形状的Tensor，初始值的形状和类型决定了这个变量的形状和类型。\n",
    "# device:这个变量的device \n",
    "# dtype:变量的元素类型 \n",
    "# graph:存放变量的图 \n",
    "# initial_value:这个变量的初始值 \n",
    "# initializer :这个变量的初始化器 \n",
    "# name:这个变量的名字 \n",
    "w=tf.Variable(initial_value=[[1,2]])\n",
    "x=tf.Variable(initial_value=[[2],[1]])\n",
    "y=tf.matmul(w,x)\n",
    "sess2=tf.Session()\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "sess2.run(init)\n",
    "print \"w:\", sess2.run(w)\n",
    "print 'x:', sess2.run(x)\n",
    "print 'y:', sess2.run(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.global_variables_initializer()\n",
    "#返回一个初始化所有全局变量的操作（Op）。要是你把图“投放进一个”session中后，你就能够通过run 这个操作来初始化所有的全局变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "y: [[ 6.]\n",
      " [15.]]\n"
     ]
    }
   ],
   "source": [
    "#四、tf.placeholder(dtype,shape=None,name=None)\n",
    "#placeholder的作用可以理解为占个位置，我并不知道这里将会是什么值，但是知道类型和形状等等一些信息，\n",
    "#然后以后用feed的方式来把这些数据“填”进去。返回的就是一个用来用来处理feeding一个值的tensor。 \n",
    "\n",
    "x=tf.placeholder(shape=[2,3],dtype=np.float32,name=\"input\")\n",
    "w=tf.constant([1,1,1],shape=[3,1],dtype=np.float32,name=\"weight\")\n",
    "print w.shape\n",
    "y=tf.matmul(x,w)\n",
    "\n",
    "input=[[1,2,3],[4,5,6]]\n",
    "with tf.Session() as sess:\n",
    "    print \"y:\", sess.run(y,feed_dict={x:input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetches表示一种取的动作，我们有时候需要在操作里面取一些输出，\n",
    "#其实就是在执行图的过程中在run（）函数里面传入一个tensor就行，然后就会输出tesnor的结果，\n",
    "#比如上面的session.run(state)就可以当做一个fetch的动作啦。当然不仅仅限于fetch一个，你也可以fetch多个tensor。\n",
    "\n",
    "#feed我们知道是喂养的意思，这个又怎么理解呢？feed的动作一般和placeholder（）函数一起用，\n",
    "#前面说过，placeholder（）起到占位的作用（参考前面的placeholder（）函数），怎么理解呢？\n",
    "#假如我有一个（堆）数据，但是我也许只知道他的类型，不知道他的值，我就可以先传进去一个类型，先把这个位置占着。等到以后再把数据“喂”给这个变量。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=tf.constant([1,2,3,4,5,6],shape=[2,3])\n",
    "sess1.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c graph <tensorflow.python.framework.ops.Graph object at 0xb32b5cfd0>\n",
      "a graph <tensorflow.python.framework.ops.Graph object at 0xb32b5cfd0>\n",
      "default graph <tensorflow.python.framework.ops.Graph object at 0xb32b5cfd0>\n"
     ]
    }
   ],
   "source": [
    "#五、图\n",
    "#一幅图中包含一些操作（Operation）对象，这些对象是计算节点。前面说过的Tensor对象，则是表示在不同的操作（operation）间的数据节点\n",
    "#你一旦开始你的任务，就已经有一个默认的图已经创建好了。而且可以通过调用tf.get_default_graph()来访问到。\n",
    "c=tf.constant([1,2])\n",
    "print \"c graph\", c.graph\n",
    "print \"a graph\", a.graph\n",
    "print \"default graph\", tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c graph: <tensorflow.python.framework.ops.Graph object at 0xb3de7e290>\n",
      "default graph: <tensorflow.python.framework.ops.Graph object at 0xb3de7e290>\n",
      "g: <tensorflow.python.framework.ops.Graph object at 0xb3de7e1d0>\n",
      "d graph: <tensorflow.python.framework.ops.Graph object at 0xb3de7e1d0>\n",
      "c graph: <tensorflow.python.framework.ops.Graph object at 0xb3de7e290>\n",
      "default graph: <tensorflow.python.framework.ops.Graph object at 0xb3de7e290>\n",
      "g2: <tensorflow.python.framework.ops.Graph object at 0xb3de70a10>\n",
      "de graph: <tensorflow.python.framework.ops.Graph object at 0xb3de70a10>\n",
      "c graph: <tensorflow.python.framework.ops.Graph object at 0xb3de7e290>\n",
      "default graph: <tensorflow.python.framework.ops.Graph object at 0xb3de7e290>\n"
     ]
    }
   ],
   "source": [
    "#Graph.as_default()\n",
    "#返回一个上下文管理器,使得这个Graph对象成为当前默认的graph.当你想在一个进程里面创建多个图的时候,就应该使用这个函数.\n",
    "#为了方便起见,一个全局的图对象被默认提供,要是你没有显式创建一个新的图的话,所有的操作(ops)都会被添加到这个默认的图里面来. \n",
    "#通过with关键字和这个方法,来让这个代码块内创建的从操作(ops)添加到这个新的图里面. \n",
    "\n",
    "c=tf.constant([1,2])\n",
    "print 'c graph:', c.graph\n",
    "print 'default graph:', tf.get_default_graph()\n",
    "\n",
    "g=tf.Graph()\n",
    "with g.as_default():\n",
    "    d=tf.constant([2,3])\n",
    "    print 'g:', g\n",
    "    print 'd graph:', d.graph\n",
    "    \n",
    "print 'c graph:', c.graph\n",
    "print 'default graph:', tf.get_default_graph()\n",
    "    \n",
    "g2=tf.Graph()\n",
    "with g2.as_default():\n",
    "    d2=tf.constant([4,5])\n",
    "    print 'g2:', g2\n",
    "    print 'de graph:', d2.graph\n",
    "    \n",
    "print 'c graph:', c.graph\n",
    "print 'default graph:', tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#六、tf.Session(target='',graph=None,config=None)\n",
    "# target:（可选）连接的执行引擎，默认是使用in-process引擎，分布式TensorFLow有更多的例子。 \n",
    "# graph: (可选)投放进的计算图（graph），要是没有指定的话，那么默认的图就会被投放到这个session。\n",
    "#要是你在同一个进程里面用了很多的图，你将为各个图使用不同的session，但是每一个graph都能够在多个session中使用。\n",
    "#在这种情况下，经常显式的传递graph参数到session的构造里面。 \n",
    "# config: (可选) A ConfigProto protocol buffer with configuration options for the session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.Session().run(fetches,feed_dict=None,options=None,)\n",
    "#fetches: 一个单独的图的元素，或者一个图的元素的列表。或者一个字典，这个字典的值是刚刚所说的一个图的元素\n",
    "#feed_dict: 一个字典，为之前“占位”的元素“喂”给值\n",
    "#如果你的fetchs参数传入的图的一个元素，那么返回一个单独的值，要是是图的一个元素列表，那么返回就是一个列表，\n",
    "#要是你传入的是一个字典，那么返回的也是一个字典，这个字典的键和你传入的字典的键是一样的。\n",
    "#函数返回的值和你传进去的fetch参数的形状是一样的，只是里面的元素是相应的值而已了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Tensor 'Const:0' shape=() dtype=int32> cannot be interpreted as a Tensor. (Tensor Tensor(\"Const:0\", shape=(), dtype=int32) is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ff38db631230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0msess1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1095\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \"\"\"\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    289\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 291\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    292\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Tensor 'Const:0' shape=() dtype=int32> cannot be interpreted as a Tensor. (Tensor Tensor(\"Const:0\", shape=(), dtype=int32) is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "#多图多Session\n",
    "#如果将下面例子的sess1.run(c1)和sess2.run(c2)中的c1和c2交换一下位置，运行会报错\n",
    "g1=tf.Graph()\n",
    "with g1.as_default():\n",
    "    a=tf.constant(3)\n",
    "sess1=tf.Session(graph=g1)\n",
    "\n",
    "g2=tf.Graph()\n",
    "with g2.as_default():\n",
    "    b=tf.constant(4)\n",
    "sess2=tf.Session(graph=g2)\n",
    "\n",
    "print sess1.run(a)\n",
    "print sess2.run(b)\n",
    "\n",
    "##报错，a不在sess中\n",
    "sess =tf.Session()\n",
    "print sess.run(a)\n",
    "\n",
    "sess1.close()\n",
    "sess2.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# def write(sess1,dict1,i):\n",
    "#     result = sess1.run(y,feed_dict=dict1)\n",
    "def write(sess1,i):\n",
    "    result = sess1.run(y)\n",
    "    df=pd.DataFrame(result,columns=['result'])\n",
    "    path='/Users/nali/pactice_p/result%s' %str(i)\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=tf.constant([1,2,3],shape=[1,3],dtype=np.float32)\n",
    "x=tf.constant([1,1,1],shape=[3,1],dtype=np.float32)\n",
    "y=tf.matmul(w,x)\n",
    "\n",
    "from multiprocessing import Pool\n",
    "sess1=tf.Session()\n",
    "sess2=tf.Session()\n",
    "all_sess=[sess1,sess2]\n",
    "\n",
    "data=np.array([i for j in range(3)]).reshape(3,1)\n",
    "dict1={x:data}\n",
    "p=Pool(2)\n",
    "for i in range(2):\n",
    "    sessi=all_sess[i]\n",
    "#     write(sess1,i)\n",
    "    p.apply_async(write,args=(sessi,i))\n",
    "p.close()\n",
    "p.join()\n",
    "\n",
    "sess1.close()\n",
    "sess2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
